{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f49a283e11648868e70906a8819a3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97d5a491e77f4ae491164a630d2449bb",
              "IPY_MODEL_22e26df7fe8f4632b64629973f1eff6a",
              "IPY_MODEL_e6058e4da0e942f183d0d68b7216b226"
            ],
            "layout": "IPY_MODEL_656016168dae4c78a0da0d93483ebab7"
          }
        },
        "97d5a491e77f4ae491164a630d2449bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a16415b752fb4546a7b550e634038866",
            "placeholder": "​",
            "style": "IPY_MODEL_a48fa6dae18946adbcc4a937452aac1e",
            "value": "generation_config.json: 100%"
          }
        },
        "22e26df7fe8f4632b64629973f1eff6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25c88cba47b94bb787e09ae80122d4fc",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9eee2e312b04e1aae729103b86e4e76",
            "value": 124
          }
        },
        "e6058e4da0e942f183d0d68b7216b226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b63489fc245a415a910f176b65aebdc5",
            "placeholder": "​",
            "style": "IPY_MODEL_1c9010f7a4d645fe9441771316788f17",
            "value": " 124/124 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "656016168dae4c78a0da0d93483ebab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a16415b752fb4546a7b550e634038866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48fa6dae18946adbcc4a937452aac1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25c88cba47b94bb787e09ae80122d4fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9eee2e312b04e1aae729103b86e4e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b63489fc245a415a910f176b65aebdc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9010f7a4d645fe9441771316788f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "073f14446a774cafac93903e9a4b50e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e183079e23a479d8f564082bc1d2cd0",
              "IPY_MODEL_f834b35cbe134a918bce8e4d234f251b",
              "IPY_MODEL_18e4e87888954e45b855ce9c5c8b636b"
            ],
            "layout": "IPY_MODEL_26df35c2c4db40f39e0106898282adda"
          }
        },
        "1e183079e23a479d8f564082bc1d2cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e88ff4fe2f4138984011debbf291cd",
            "placeholder": "​",
            "style": "IPY_MODEL_1cbabdfa83804362be33be24c5317718",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f834b35cbe134a918bce8e4d234f251b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6548ee7e51f42b0975166007ace383e",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_250d2011eb9942a5adb866507711863a",
            "value": 26
          }
        },
        "18e4e87888954e45b855ce9c5c8b636b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0283fb111e8944b9bc3077b6e322423f",
            "placeholder": "​",
            "style": "IPY_MODEL_d834c6cd63944e8abb00f964f01ba6ef",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.41kB/s]"
          }
        },
        "26df35c2c4db40f39e0106898282adda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e88ff4fe2f4138984011debbf291cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cbabdfa83804362be33be24c5317718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6548ee7e51f42b0975166007ace383e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250d2011eb9942a5adb866507711863a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0283fb111e8944b9bc3077b6e322423f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d834c6cd63944e8abb00f964f01ba6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d16ba3827ba40c7a0aa517bfd2df5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d7661c7fb1b49c7b0738aa06b350b66",
              "IPY_MODEL_f48d065fca1f45dca69a1f616a3d47c6",
              "IPY_MODEL_266fac40d9e94b1eab163c8629967347"
            ],
            "layout": "IPY_MODEL_f63a4d88c26447aeaf1bf6c67fad1134"
          }
        },
        "2d7661c7fb1b49c7b0738aa06b350b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da51f076a33540629c4c111928d2b5c3",
            "placeholder": "​",
            "style": "IPY_MODEL_62901e9724e74b1b91e4921c791edef7",
            "value": "vocab.json: 100%"
          }
        },
        "f48d065fca1f45dca69a1f616a3d47c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12dc29c5d76447a4a06ae6cd2d49ba7d",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c2694d585704d19a9f2558338b100c2",
            "value": 1042301
          }
        },
        "266fac40d9e94b1eab163c8629967347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c06cf3b98d144799cf1baf340397327",
            "placeholder": "​",
            "style": "IPY_MODEL_14fa23f9858548d6a92fa0e192022302",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 18.3MB/s]"
          }
        },
        "f63a4d88c26447aeaf1bf6c67fad1134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da51f076a33540629c4c111928d2b5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62901e9724e74b1b91e4921c791edef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12dc29c5d76447a4a06ae6cd2d49ba7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2694d585704d19a9f2558338b100c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c06cf3b98d144799cf1baf340397327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14fa23f9858548d6a92fa0e192022302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0777facfe89d4df7a4bf54a85eacb105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f72ab0086c84e53b1a2b3b504d39e67",
              "IPY_MODEL_90c16573ee0249648c05693a31e1d648",
              "IPY_MODEL_e820c0cbfd8c4edc80480d38bd6c50f9"
            ],
            "layout": "IPY_MODEL_f279eb6997c04a5aa4a542a2a4a68a90"
          }
        },
        "3f72ab0086c84e53b1a2b3b504d39e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8721ad5bfcc4d69abef5ac571920ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_04d628872c1b400ea2060982c661f737",
            "value": "merges.txt: 100%"
          }
        },
        "90c16573ee0249648c05693a31e1d648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2870b216f44b39859741e7ba796ba1",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cadb2f632e024f47a065aa128105ac57",
            "value": 456318
          }
        },
        "e820c0cbfd8c4edc80480d38bd6c50f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23de96bde76c46869149d563a4aba5d5",
            "placeholder": "​",
            "style": "IPY_MODEL_f1db7f60917b4fe98480c5ed60e070e6",
            "value": " 456k/456k [00:00&lt;00:00, 32.7MB/s]"
          }
        },
        "f279eb6997c04a5aa4a542a2a4a68a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8721ad5bfcc4d69abef5ac571920ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d628872c1b400ea2060982c661f737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a2870b216f44b39859741e7ba796ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cadb2f632e024f47a065aa128105ac57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23de96bde76c46869149d563a4aba5d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1db7f60917b4fe98480c5ed60e070e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2c257656eb14989a805bd2d28194455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69512194ec964f818fcd0a17f5fd3c53",
              "IPY_MODEL_f4a2e73a6a8c47cb8616bd5485f729f2",
              "IPY_MODEL_0dfe74408d6044c9924d14c4d6ee02c6"
            ],
            "layout": "IPY_MODEL_151ec2c12fa24e05a8c63f34d0f095d6"
          }
        },
        "69512194ec964f818fcd0a17f5fd3c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0227379a4bf34c34a359df823a144acb",
            "placeholder": "​",
            "style": "IPY_MODEL_5fa86abbc7c14edc88eba9ad9e5a8d5b",
            "value": "tokenizer.json: 100%"
          }
        },
        "f4a2e73a6a8c47cb8616bd5485f729f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e260751191964aab8b35e63885935c22",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68af3d8933ba4b20a3e3f9e8e0e1bb64",
            "value": 1355256
          }
        },
        "0dfe74408d6044c9924d14c4d6ee02c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8d166c48c81496e9754dfedda0af3e4",
            "placeholder": "​",
            "style": "IPY_MODEL_3f422c0e3dcd46b897ba29c24067cba2",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 41.8MB/s]"
          }
        },
        "151ec2c12fa24e05a8c63f34d0f095d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0227379a4bf34c34a359df823a144acb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa86abbc7c14edc88eba9ad9e5a8d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e260751191964aab8b35e63885935c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68af3d8933ba4b20a3e3f9e8e0e1bb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8d166c48c81496e9754dfedda0af3e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f422c0e3dcd46b897ba29c24067cba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anushkapatwa/CSCI-167/blob/main/Notebooks/Chap12/12_4_Decoding_Strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Notebook 12.4: Decoding strategies**\n",
        "\n",
        "This practical investigates neural decoding from transformer models.  \n",
        "\n",
        "Work through the cells below, running each cell in turn. In various places you will see the words \"TODO\". Follow the instructions at these places and make predictions about what is going to happen or write code to complete the functions.\n",
        "\n",
        "Contact me at udlbookmail@gmail.com if you find any mistakes or have any suggestions."
      ],
      "metadata": {
        "id": "RnIUiieJWu6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "7abjZ9pMVj3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570e734d-a9cd-48bf-a7db-e0710d26369d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, set_seed\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sMOyD0zem2Ef"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "pZgfxbzKWNSR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302,
          "referenced_widgets": [
            "0fbcd97717cb4c40affbbe89cab5da32",
            "539a69a74dff4723b1d483821ec35cd6",
            "7f49a283e11648868e70906a8819a3f4",
            "97d5a491e77f4ae491164a630d2449bb",
            "22e26df7fe8f4632b64629973f1eff6a",
            "e6058e4da0e942f183d0d68b7216b226",
            "656016168dae4c78a0da0d93483ebab7",
            "a16415b752fb4546a7b550e634038866",
            "a48fa6dae18946adbcc4a937452aac1e",
            "25c88cba47b94bb787e09ae80122d4fc",
            "e9eee2e312b04e1aae729103b86e4e76",
            "b63489fc245a415a910f176b65aebdc5",
            "1c9010f7a4d645fe9441771316788f17",
            "073f14446a774cafac93903e9a4b50e3",
            "1e183079e23a479d8f564082bc1d2cd0",
            "f834b35cbe134a918bce8e4d234f251b",
            "18e4e87888954e45b855ce9c5c8b636b",
            "26df35c2c4db40f39e0106898282adda",
            "42e88ff4fe2f4138984011debbf291cd",
            "1cbabdfa83804362be33be24c5317718",
            "e6548ee7e51f42b0975166007ace383e",
            "250d2011eb9942a5adb866507711863a",
            "0283fb111e8944b9bc3077b6e322423f",
            "d834c6cd63944e8abb00f964f01ba6ef",
            "7d16ba3827ba40c7a0aa517bfd2df5be",
            "2d7661c7fb1b49c7b0738aa06b350b66",
            "f48d065fca1f45dca69a1f616a3d47c6",
            "266fac40d9e94b1eab163c8629967347",
            "f63a4d88c26447aeaf1bf6c67fad1134",
            "da51f076a33540629c4c111928d2b5c3",
            "62901e9724e74b1b91e4921c791edef7",
            "12dc29c5d76447a4a06ae6cd2d49ba7d",
            "2c2694d585704d19a9f2558338b100c2",
            "0c06cf3b98d144799cf1baf340397327",
            "14fa23f9858548d6a92fa0e192022302",
            "0777facfe89d4df7a4bf54a85eacb105",
            "3f72ab0086c84e53b1a2b3b504d39e67",
            "90c16573ee0249648c05693a31e1d648",
            "e820c0cbfd8c4edc80480d38bd6c50f9",
            "f279eb6997c04a5aa4a542a2a4a68a90",
            "f8721ad5bfcc4d69abef5ac571920ddb",
            "04d628872c1b400ea2060982c661f737",
            "0a2870b216f44b39859741e7ba796ba1",
            "cadb2f632e024f47a065aa128105ac57",
            "23de96bde76c46869149d563a4aba5d5",
            "f1db7f60917b4fe98480c5ed60e070e6",
            "e2c257656eb14989a805bd2d28194455",
            "69512194ec964f818fcd0a17f5fd3c53",
            "f4a2e73a6a8c47cb8616bd5485f729f2",
            "0dfe74408d6044c9924d14c4d6ee02c6",
            "151ec2c12fa24e05a8c63f34d0f095d6",
            "0227379a4bf34c34a359df823a144acb",
            "5fa86abbc7c14edc88eba9ad9e5a8d5b",
            "e260751191964aab8b35e63885935c22",
            "68af3d8933ba4b20a3e3f9e8e0e1bb64",
            "b8d166c48c81496e9754dfedda0af3e4",
            "3f422c0e3dcd46b897ba29c24067cba2"
          ]
        },
        "outputId": "8101330a-6031-4061-e792-224e977f043d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'TypeError: Failed to fetch'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fbcd97717cb4c40affbbe89cab5da32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "539a69a74dff4723b1d483821ec35cd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f49a283e11648868e70906a8819a3f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "073f14446a774cafac93903e9a4b50e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d16ba3827ba40c7a0aa517bfd2df5be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0777facfe89d4df7a4bf54a85eacb105"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2c257656eb14989a805bd2d28194455"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoding from GPT2\n",
        "\n",
        "This tutorial investigates how to use GPT2 (the forerunner of GPT3) to generate text.  There are a number of ways to do this that trade-off the realism of the text against the amount of variation.\n",
        "\n",
        "At every stage, GPT2 takes an input string and returns a probability for each of the possible subsequent tokens.  We can choose what to do with these probability.  We could always *greedily choose* the most likely next token, or we could draw a *sample* randomly according to the probabilities.  There are also intermediate strategies such as *top-k sampling* and *nucleus sampling*, that have some controlled randomness.\n",
        "\n",
        "We'll also investigate *beam search* -- the idea is that rather than greedily take the next best token at each stage, we maintain a set of hypotheses  (beams)as we add each subsequent token and return the most likely overall hypothesis.  This is not necessarily the same result we get from greedily choosing the next token."
      ],
      "metadata": {
        "id": "TfhAGy0TXEvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's investigate the token themselves.  The code below prints out the vocabulary size and shows 20 random tokens.  "
      ],
      "metadata": {
        "id": "vsmO9ptzau3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "print(\"Number of tokens in dictionary = %d\"%(tokenizer.vocab_size))\n",
        "for i in range(20):\n",
        "  index = np.random.randint(tokenizer.vocab_size)\n",
        "  print(\"Token: %d \"%(index)+tokenizer.decode(torch.tensor(index), skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "dmmBNS5GY_yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cddeb78-70a9-4466-9b1c-fdbb24acf8ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens in dictionary = 50257\n",
            "Token: 33003  Mormons\n",
            "Token: 12172  cam\n",
            "Token: 5192  trig\n",
            "Token: 32511 ojure\n",
            "Token: 50057  gist\n",
            "Token: 43723  Petition\n",
            "Token: 7813  sin\n",
            "Token: 21440  Witness\n",
            "Token: 32912  Remy\n",
            "Token: 20609 isure\n",
            "Token: 49100  creeps\n",
            "Token: 7751  fasc\n",
            "Token: 43757  Alc\n",
            "Token: 31228  messenger\n",
            "Token: 36230  SYSTEM\n",
            "Token: 32025  precipitation\n",
            "Token: 21758  cores\n",
            "Token: 45413  Forestry\n",
            "Token: 35730  guru\n",
            "Token: 8444  Disc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling\n",
        "\n",
        "Each time we run GPT2 it will take in a set of tokens, and return a probability over each of the possible next tokens.  The simplest thing we could do is to just draw a sample from this probability distribution each time."
      ],
      "metadata": {
        "id": "MUM3kLEjbTso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_next_token(input_tokens, model, tokenizer):\n",
        "    # Run model to get prediction over next output\n",
        "    outputs = model(\n",
        "        input_ids=input_tokens['input_ids'],\n",
        "        attention_mask=input_tokens['attention_mask']\n",
        "    )\n",
        "\n",
        "    # Find prediction probabilities for the next token\n",
        "    prob_over_tokens = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "\n",
        "    # --- FIXED PART: Draw a random token according to the probability distribution ---\n",
        "    next_token = [np.random.choice(len(prob_over_tokens), p=prob_over_tokens)]\n",
        "    # -------------------------------------------------------------------------------\n",
        "\n",
        "    # Append token to sentence\n",
        "    output_tokens = input_tokens\n",
        "    output_tokens[\"input_ids\"] = torch.cat(\n",
        "        (output_tokens['input_ids'], torch.tensor([next_token])), dim=1\n",
        "    )\n",
        "    output_tokens['attention_mask'] = torch.cat(\n",
        "        (output_tokens['attention_mask'], torch.tensor([[1]])), dim=1\n",
        "    )\n",
        "\n",
        "    # Probability of the chosen token\n",
        "    output_tokens['last_token_prob'] = prob_over_tokens[next_token[0]]\n",
        "\n",
        "    return output_tokens\n"
      ],
      "metadata": {
        "id": "TIyNgg0FkJKO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expected output:\n",
        "# \"The best thing about Bath is that they don't even change or shrink anymore.\"\n",
        "\n",
        "set_seed(0)\n",
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "for i in range(10):\n",
        "    input_tokens = sample_next_token(input_tokens, model, tokenizer)\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))\n",
        "\n"
      ],
      "metadata": {
        "id": "BHs-IWaz9MNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e86f53c-d806-48cb-feaf-c044ea7ce15c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best thing about Bath is that\n",
            "The best thing about Bath is that they\n",
            "The best thing about Bath is that they don\n",
            "The best thing about Bath is that they don't\n",
            "The best thing about Bath is that they don't even\n",
            "The best thing about Bath is that they don't even change\n",
            "The best thing about Bath is that they don't even change or\n",
            "The best thing about Bath is that they don't even change or shrink\n",
            "The best thing about Bath is that they don't even change or shrink anymore\n",
            "The best thing about Bath is that they don't even change or shrink anymore.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "\n",
        "# TODO Change this range() value to generate more or fewer tokens:\n",
        "for i in range(10):   # try 5, 20, 50, etc.\n",
        "    input_tokens = sample_next_token(input_tokens, model, tokenizer)\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "yN98_7WqbvIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2109a060-618f-45c2-ee86-7c4700c6ed1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best thing about Bath is your\n",
            "The best thing about Bath is your kids\n",
            "The best thing about Bath is your kids will\n",
            "The best thing about Bath is your kids will definitely\n",
            "The best thing about Bath is your kids will definitely be\n",
            "The best thing about Bath is your kids will definitely be up\n",
            "The best thing about Bath is your kids will definitely be up the\n",
            "The best thing about Bath is your kids will definitely be up the chim\n",
            "The best thing about Bath is your kids will definitely be up the chimney\n",
            "The best thing about Bath is your kids will definitely be up the chimney floor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Greedy token selection\n",
        "\n",
        "You probably (correctly) got the impression that the text from pure sampling of the probability model can be kind of random.  How about if we choose most likely token at each step?\n"
      ],
      "metadata": {
        "id": "7eHFLCeZcmmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_next_token(input_tokens, model, tokenizer):\n",
        "    # Run model to get prediction over next output\n",
        "    outputs = model(\n",
        "        input_ids=input_tokens['input_ids'],\n",
        "        attention_mask=input_tokens['attention_mask']\n",
        "    )\n",
        "\n",
        "    # Find prediction\n",
        "    prob_over_tokens = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "\n",
        "    # TODO -- find the token index with the maximum probability\n",
        "    # Use numpy.argmax\n",
        "    next_token = [np.argmax(prob_over_tokens)]   # ← FIXED LINE\n",
        "\n",
        "    # Append token to sentence\n",
        "    output_tokens = input_tokens\n",
        "    output_tokens[\"input_ids\"] = torch.cat(\n",
        "        (output_tokens['input_ids'], torch.tensor([next_token])), dim=1\n",
        "    )\n",
        "    output_tokens['attention_mask'] = torch.cat(\n",
        "        (output_tokens['attention_mask'], torch.tensor([[1]])), dim=1\n",
        "    )\n",
        "\n",
        "    # Probability of chosen token\n",
        "    output_tokens['last_token_prob'] = prob_over_tokens[next_token[0]]\n",
        "\n",
        "    return output_tokens\n"
      ],
      "metadata": {
        "id": "OhRzynEjxpZF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expected output:\n",
        "# The best thing about Bath is that it's a place where you can go to\n",
        "set_seed(0)\n",
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "for i in range(10):\n",
        "    input_tokens = get_best_next_token(input_tokens, model, tokenizer)\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "gKB1Mgndj-Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08de3de-df0f-47d6-acc7-b09c5cb6a7a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best thing about Bath is that\n",
            "The best thing about Bath is that it\n",
            "The best thing about Bath is that it's\n",
            "The best thing about Bath is that it's a\n",
            "The best thing about Bath is that it's a place\n",
            "The best thing about Bath is that it's a place where\n",
            "The best thing about Bath is that it's a place where you\n",
            "The best thing about Bath is that it's a place where you can\n",
            "The best thing about Bath is that it's a place where you can go\n",
            "The best thing about Bath is that it's a place where you can go to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "\n",
        "# TODO Experiment with changing this line:\n",
        "for i in range(10):   # try 5, 20, 30, etc.\n",
        "    input_tokens = get_best_next_token(input_tokens, model, tokenizer)\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "L1YHKaYFfC0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c20705-8bac-4687-d3d5-4aa0a7630811"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best thing about Bath is that\n",
            "The best thing about Bath is that it\n",
            "The best thing about Bath is that it's\n",
            "The best thing about Bath is that it's a\n",
            "The best thing about Bath is that it's a place\n",
            "The best thing about Bath is that it's a place where\n",
            "The best thing about Bath is that it's a place where you\n",
            "The best thing about Bath is that it's a place where you can\n",
            "The best thing about Bath is that it's a place where you can go\n",
            "The best thing about Bath is that it's a place where you can go to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top-K sampling\n",
        "\n",
        "You probably noticed that the greedy strategy produces quite realistic text, but it's kind of boring.  It produces generic answers.  Also, if this was a chatbot, then we wouldn't necessarily want it to produce the same answer to a question each time.  \n",
        "\n",
        "Top-K sampling is a compromise strategy that samples randomly from the top K most probable tokens.  We could just choose them with a uniform distribution, or (as here) we could sample them according to their original probabilities."
      ],
      "metadata": {
        "id": "1ORFXYX_gBDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_token(input_tokens, model, tokenizer, k=20):\n",
        "    # Run model to get prediction over next output\n",
        "    outputs = model(\n",
        "        input_ids=input_tokens['input_ids'],\n",
        "        attention_mask=input_tokens['attention_mask']\n",
        "    )\n",
        "\n",
        "    # Softmax probabilities for the next token\n",
        "    prob_over_tokens = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "\n",
        "    # ---- TOP-K SAMPLING IMPLEMENTATION ----\n",
        "\n",
        "    # 1. Sort probabilities descending\n",
        "    sorted_prob_over_tokens = np.sort(prob_over_tokens)[::-1]\n",
        "\n",
        "    # 2. Probability threshold = k-th largest probability\n",
        "    kth_prob_value = sorted_prob_over_tokens[k-1]\n",
        "\n",
        "    # 3. Zero-out probabilities outside the top-k\n",
        "    prob_over_tokens[prob_over_tokens < kth_prob_value] = 0\n",
        "\n",
        "    # 4. Re-normalize\n",
        "    prob_over_tokens = prob_over_tokens / prob_over_tokens.sum()\n",
        "\n",
        "    # 5. Sample\n",
        "    next_token = np.random.choice(len(prob_over_tokens), 1, replace=False, p=prob_over_tokens)\n",
        "\n",
        "    # ---- Append token to output ----\n",
        "    output_tokens = input_tokens\n",
        "    output_tokens[\"input_ids\"] = torch.cat(\n",
        "        (output_tokens['input_ids'], torch.tensor([next_token])), dim=1\n",
        "    )\n",
        "    output_tokens['attention_mask'] = torch.cat(\n",
        "        (output_tokens['attention_mask'], torch.tensor([[1]])), dim=1\n",
        "    )\n",
        "    output_tokens['last_token_prob'] = prob_over_tokens[next_token]\n",
        "\n",
        "    return output_tokens\n"
      ],
      "metadata": {
        "id": "7RFbn6c-0Z4v"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expected output:\n",
        "# The best thing about Bath is that you get to see all the beautiful faces of\n",
        "\n",
        "set_seed(0)\n",
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "for i in range(10):\n",
        "    input_tokens = get_top_k_token(input_tokens, model, tokenizer, k=10)\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "G3w1GVED4HYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acd3178-f670-4b1b-fd79-c7324b2d1344"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-406133515.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  (output_tokens['input_ids'], torch.tensor([next_token])), dim=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best thing about Bath is that\n",
            "The best thing about Bath is that you\n",
            "The best thing about Bath is that you get\n",
            "The best thing about Bath is that you get to\n",
            "The best thing about Bath is that you get to see\n",
            "The best thing about Bath is that you get to see all\n",
            "The best thing about Bath is that you get to see all the\n",
            "The best thing about Bath is that you get to see all the beautiful\n",
            "The best thing about Bath is that you get to see all the beautiful faces\n",
            "The best thing about Bath is that you get to see all the beautiful faces of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "set_seed(0)\n",
        "\n",
        "# TODO: Change the starting sentence to see different behaviors\n",
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "\n",
        "# TODO: Experiment with different values of k here\n",
        "for i in range(10):\n",
        "    input_tokens = get_top_k_token(input_tokens, model, tokenizer, k=10)  # try k=3, k=50, k=5000\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "RySu2bzqpW9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed44390d-d1b7-4a11-ab38-46be382b097d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best thing about Bath is that\n",
            "The best thing about Bath is that you\n",
            "The best thing about Bath is that you get\n",
            "The best thing about Bath is that you get to\n",
            "The best thing about Bath is that you get to see\n",
            "The best thing about Bath is that you get to see all\n",
            "The best thing about Bath is that you get to see all the\n",
            "The best thing about Bath is that you get to see all the beautiful\n",
            "The best thing about Bath is that you get to see all the beautiful faces\n",
            "The best thing about Bath is that you get to see all the beautiful faces of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nucleus sampling\n",
        "\n",
        "Top-K sampling has the disadvantage that sometimes there are only a few plausible next tokens, and sometimes there are a lot.  How do we adapt to this situation?  One way is to sample from a fixed proportion of the probability mass.  That is we order the tokens in terms of probability and cut off the possibility of sampling when the cumulative sum is greater than a threshold.\n",
        "\n",
        "This way, we adapt the number of possible tokens that we can choose."
      ],
      "metadata": {
        "id": "fOHak_QJfU-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nucleus_sampling_token(input_tokens, model, tokenizer, thresh=0.25):\n",
        "    # Run model to get prediction over next output\n",
        "    outputs = model(\n",
        "        input_ids=input_tokens['input_ids'],\n",
        "        attention_mask=input_tokens['attention_mask']\n",
        "    )\n",
        "\n",
        "    # Softmax to get probabilities\n",
        "    prob_over_tokens = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "\n",
        "    # --- NUCLEUS (TOP-P) SAMPLING IMPLEMENTATION ---\n",
        "\n",
        "    # 1. Sort probabilities from largest to smallest\n",
        "    sorted_probs_decreasing = np.sort(prob_over_tokens)[::-1]\n",
        "\n",
        "    # 2. Cumulative sum of sorted probs\n",
        "    cum_sum_probs = np.cumsum(sorted_probs_decreasing)\n",
        "\n",
        "    # 3. Find first index where cumulative sum exceeds threshold p\n",
        "    thresh_index = np.argmax(cum_sum_probs > thresh)\n",
        "    print(\"Choosing from %d tokens\" % (thresh_index))\n",
        "\n",
        "    # 4. Probability value at threshold index\n",
        "    thresh_prob = sorted_probs_decreasing[thresh_index]\n",
        "\n",
        "    # 5. Zero out probabilities below this threshold\n",
        "    prob_over_tokens[prob_over_tokens < thresh_prob] = 0\n",
        "\n",
        "    # 6. Renormalize so they sum to 1\n",
        "    prob_over_tokens = prob_over_tokens / np.sum(prob_over_tokens)\n",
        "\n",
        "    # 7. Sample a token\n",
        "    next_token = np.random.choice(len(prob_over_tokens), 1, replace=False, p=prob_over_tokens)\n",
        "\n",
        "    # --- Append token to output ---\n",
        "    output_tokens = input_tokens\n",
        "    output_tokens[\"input_ids\"] = torch.cat(\n",
        "        (output_tokens['input_ids'], torch.tensor([next_token])), dim=1\n",
        "    )\n",
        "    output_tokens['attention_mask'] = torch.cat(\n",
        "        (output_tokens['attention_mask'], torch.tensor([[1]])), dim=1\n",
        "    )\n",
        "    output_tokens['last_token_prob'] = prob_over_tokens[next_token]\n",
        "\n",
        "    return output_tokens\n"
      ],
      "metadata": {
        "id": "PtxS4kNDyUcm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expected output:\n",
        "# The best thing about Bath is that it's not a city that has been around\n",
        "set_seed(0)\n",
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "for i in range(10):\n",
        "    input_tokens = get_nucleus_sampling_token(input_tokens, model, tokenizer, thresh = 0.2)\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "K2Vk1Ly40S6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbe1d05-aea7-4799-a981-4b8edb66c5d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that\n",
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that it\n",
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that it's\n",
            "Choosing from 2 tokens\n",
            "The best thing about Bath is that it's not\n",
            "Choosing from 1 tokens\n",
            "The best thing about Bath is that it's not a\n",
            "Choosing from 25 tokens\n",
            "The best thing about Bath is that it's not a city\n",
            "Choosing from 2 tokens\n",
            "The best thing about Bath is that it's not a city that\n",
            "Choosing from 1 tokens\n",
            "The best thing about Bath is that it's not a city that has\n",
            "Choosing from 1 tokens\n",
            "The best thing about Bath is that it's not a city that has been\n",
            "Choosing from 11 tokens\n",
            "The best thing about Bath is that it's not a city that has been around\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "for i in range(10):\n",
        "    input_tokens = get_nucleus_sampling_token(input_tokens, model, tokenizer, thresh = 0.2)\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "eQNNHe14wDvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7df1f9-533d-4f01-a479-0649dd6b667c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that\n",
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that it\n",
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that it's\n",
            "Choosing from 2 tokens\n",
            "The best thing about Bath is that it's so\n",
            "Choosing from 3 tokens\n",
            "The best thing about Bath is that it's so much\n",
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that it's so much more\n",
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that it's so much more than\n",
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that it's so much more than just\n",
            "Choosing from 0 tokens\n",
            "The best thing about Bath is that it's so much more than just a\n",
            "Choosing from 4 tokens\n",
            "The best thing about Bath is that it's so much more than just a beach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beam search\n",
        "\n",
        "All of the methods we've seen so far choose the tokens one by one.  But this isn't necessarily sensible.  Even greedily choosing the best token doesn't necessarily retrieve the sequence with the highest probability.  It might be that the most likely token only has very unlikely tokens following it.\n",
        "\n",
        "Beam search maintains $K$ hypotheses about the best possible continuation.  It starts with the top $K$ continuations.  Then for each of those, it finds the top K continuations, giving $K^2$ hypotheses.  Then it retains just the top $K$ of these so that the number of hypotheses stays the same."
      ],
      "metadata": {
        "id": "WMMNeLixwlgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_kth_most_likely_token(input_tokens, model, tokenizer, k):\n",
        "    # Run model to get prediction over next output\n",
        "    outputs = model(\n",
        "        input_ids=input_tokens['input_ids'],\n",
        "        attention_mask=input_tokens['attention_mask']\n",
        "    )\n",
        "\n",
        "    # Softmax probabilities for next token\n",
        "    prob_over_tokens = F.softmax(outputs.logits, dim=-1).detach().numpy()[0, -1]\n",
        "\n",
        "    # --- FIXED TODOs ---\n",
        "\n",
        "    # 1. Sort probabilities from largest to smallest\n",
        "    sorted_prob_over_tokens = np.sort(prob_over_tokens)[::-1]\n",
        "\n",
        "    # 2. Get the k-th most likely probability value\n",
        "    kth_prob_value = sorted_prob_over_tokens[k]\n",
        "\n",
        "    # 3. Find the token ID with this probability\n",
        "    next_token = np.where(prob_over_tokens == kth_prob_value)[0]\n",
        "\n",
        "    # --- Append token to output ---\n",
        "    output_tokens = input_tokens\n",
        "    output_tokens[\"input_ids\"] = torch.cat(\n",
        "        (output_tokens['input_ids'], torch.tensor([next_token])), dim=1\n",
        "    )\n",
        "    output_tokens['attention_mask'] = torch.cat(\n",
        "        (output_tokens['attention_mask'], torch.tensor([[1]])), dim=1\n",
        "    )\n",
        "    output_tokens['last_token_prob'] = prob_over_tokens[next_token]\n",
        "\n",
        "    # Keep running log-probabilities (for beam search scoring)\n",
        "    output_tokens['log_prob'] = output_tokens['log_prob'] + np.log(prob_over_tokens[next_token])\n",
        "\n",
        "    return output_tokens\n"
      ],
      "metadata": {
        "id": "sAI2bClXCe2F"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can test this code and see that if we choose the 2nd most likely (K=1) token each time\n",
        "# then we get much better generation results than if we choose the 2001st most likely token\n",
        "\n",
        "# Expected output:\n",
        "# The best thing about Bath is the way you get the most bang outta the\n",
        "set_seed(0)\n",
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "input_tokens['log_prob'] = 0.0\n",
        "for i in range(10):\n",
        "    input_tokens = get_kth_most_likely_token(input_tokens, model, tokenizer, k=1)\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))\n",
        "\n",
        "# Expected output:\n",
        "# The best thing about Bath is mixed profits partnerships» buy generic+ Honda throttlecont\n",
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "input_tokens['log_prob'] = 0.0\n",
        "for i in range(10):\n",
        "    input_tokens = get_kth_most_likely_token(input_tokens, model, tokenizer, k=2000)\n",
        "    print(tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "6kSc0WrTELMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec689414-93ff-4a7e-e474-bec3dc579edf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best thing about Bath is the\n",
            "The best thing about Bath is the way\n",
            "The best thing about Bath is the way you\n",
            "The best thing about Bath is the way you get\n",
            "The best thing about Bath is the way you get the\n",
            "The best thing about Bath is the way you get the most\n",
            "The best thing about Bath is the way you get the most bang\n",
            "The best thing about Bath is the way you get the most bang out\n",
            "The best thing about Bath is the way you get the most bang outta\n",
            "The best thing about Bath is the way you get the most bang outta the\n",
            "The best thing about Bath is mixed\n",
            "The best thing about Bath is mixed profits\n",
            "The best thing about Bath is mixed profits partnerships\n",
            "The best thing about Bath is mixed profits partnerships»\n",
            "The best thing about Bath is mixed profits partnerships» buy\n",
            "The best thing about Bath is mixed profits partnerships» buy generic\n",
            "The best thing about Bath is mixed profits partnerships» buy generic+\n",
            "The best thing about Bath is mixed profits partnerships» buy generic+ Honda\n",
            "The best thing about Bath is mixed profits partnerships» buy generic+ Honda throttle\n",
            "The best thing about Bath is mixed profits partnerships» buy generic+ Honda throttlecont\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out each beam plus the log probability\n",
        "def print_beams(beams):\n",
        "    for index, beam in enumerate(beams):\n",
        "        print(\"Beam %d, Prob %3.3f: \" % (index, beam['log_prob']) +\n",
        "              tokenizer.decode(beam[\"input_ids\"][0], skip_special_tokens=True))\n",
        "    print('---')\n",
        "\n",
        "\n",
        "def do_beam_search(input_tokens_in, model, tokenizer, n_beam=5, beam_length=10):\n",
        "    # Make a *copy* so we don't modify the original input\n",
        "    input_tokens = dict(input_tokens_in)\n",
        "    input_tokens['log_prob'] = 0.0\n",
        "\n",
        "    # Initialize beams with the top n_beam most likely next tokens\n",
        "    beams = [None] * n_beam\n",
        "    for c_k in range(n_beam):\n",
        "        beams[c_k] = dict(input_tokens)                     # copy\n",
        "        beams[c_k] = get_kth_most_likely_token(beams[c_k], model, tokenizer, c_k)\n",
        "\n",
        "    print_beams(beams)\n",
        "\n",
        "    # Expand each beam for beam_length - 1 steps\n",
        "    for c_pos in range(beam_length - 1):\n",
        "        beams_all = [None] * (n_beam * n_beam)\n",
        "        log_probs_all = np.zeros(n_beam * n_beam)\n",
        "\n",
        "        # Expand every beam with top n_beam continuations\n",
        "        for c_beam in range(n_beam):\n",
        "            for c_k in range(n_beam):\n",
        "                new_beam = get_kth_most_likely_token(beams[c_beam], model, tokenizer, c_k)\n",
        "                beams_all[c_beam * n_beam + c_k] = dict(new_beam)\n",
        "                log_probs_all[c_beam * n_beam + c_k] = new_beam['log_prob']\n",
        "\n",
        "        # Choose best n_beam beams by highest log_prob\n",
        "        sorted_index = np.argsort(log_probs_all * -1)\n",
        "\n",
        "        for c_k in range(n_beam):\n",
        "            beams[c_k] = dict(beams_all[sorted_index[c_k]])\n",
        "\n",
        "        print_beams(beams)\n",
        "\n",
        "    return beams[0]\n"
      ],
      "metadata": {
        "id": "Y4hFfwPFFxka"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expected output:\n",
        "# The best thing about Bath is that it's a place where you don't have to\n",
        "\n",
        "set_seed(0)\n",
        "input_txt = \"The best thing about Bath is\"\n",
        "input_tokens = tokenizer(input_txt, return_tensors='pt')\n",
        "\n",
        "# Now let's call the beam search\n",
        "# It takes a while as it has to run the model multiple times to add a token\n",
        "n_beams = 5\n",
        "best_beam = do_beam_search(input_tokens,model,tokenizer)\n",
        "print(\"Beam search result:\")\n",
        "print(tokenizer.decode(best_beam[\"input_ids\"][0], skip_special_tokens=True))\n",
        "\n",
        "# You should see that the best answer is not the same as the greedy solution we found above\n"
      ],
      "metadata": {
        "id": "0YWKwZmz4NXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4a0406-19b7-4448-ad35-0a9f9a55458a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-711121882.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(\"Beam %d, Prob %3.3f: \" % (index, beam['log_prob']) +\n",
            "/tmp/ipython-input-711121882.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  log_probs_all[c_beam * n_beam + c_k] = new_beam['log_prob']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam 0, Prob -0.727: The best thing about Bath is that\n",
            "Beam 1, Prob -2.161: The best thing about Bath is the\n",
            "Beam 2, Prob -3.177: The best thing about Bath is it\n",
            "Beam 3, Prob -3.468: The best thing about Bath is how\n",
            "Beam 4, Prob -3.536: The best thing about Bath is you\n",
            "---\n",
            "Beam 0, Prob -1.899: The best thing about Bath is that it\n",
            "Beam 1, Prob -3.931: The best thing about Bath is it's\n",
            "Beam 2, Prob -4.079: The best thing about Bath is that it is\n",
            "Beam 3, Prob -4.433: The best thing about Bath is the fact\n",
            "Beam 4, Prob -4.553: The best thing about Bath is you can\n",
            "---\n",
            "Beam 0, Prob -2.740: The best thing about Bath is that it's\n",
            "Beam 1, Prob -4.657: The best thing about Bath is the fact that\n",
            "Beam 2, Prob -5.331: The best thing about Bath is that it's not\n",
            "Beam 3, Prob -6.227: The best thing about Bath is it's a\n",
            "Beam 4, Prob -6.264: The best thing about Bath is that it is a\n",
            "---\n",
            "Beam 0, Prob -4.938: The best thing about Bath is that it's a\n",
            "Beam 1, Prob -6.012: The best thing about Bath is the fact that it\n",
            "Beam 2, Prob -7.313: The best thing about Bath is that it's not a\n",
            "Beam 3, Prob -7.907: The best thing about Bath is the fact that it is\n",
            "Beam 4, Prob -8.110: The best thing about Bath is that it's a great\n",
            "---\n",
            "Beam 0, Prob -6.919: The best thing about Bath is the fact that it's\n",
            "Beam 1, Prob -7.764: The best thing about Bath is that it's a place\n",
            "Beam 2, Prob -8.930: The best thing about Bath is that it's a great place\n",
            "Beam 3, Prob -9.479: The best thing about Bath is that it's a place that\n",
            "Beam 4, Prob -9.543: The best thing about Bath is the fact that it's not\n",
            "---\n",
            "Beam 0, Prob -8.451: The best thing about Bath is that it's a place where\n",
            "Beam 1, Prob -9.125: The best thing about Bath is the fact that it's a\n",
            "Beam 2, Prob -9.285: The best thing about Bath is that it's a great place to\n",
            "Beam 3, Prob -10.536: The best thing about Bath is that it's a place where people\n",
            "Beam 4, Prob -11.255: The best thing about Bath is that it's a place that's\n",
            "---\n",
            "Beam 0, Prob -9.306: The best thing about Bath is that it's a place where you\n",
            "Beam 1, Prob -11.327: The best thing about Bath is that it's a place where people can\n",
            "Beam 2, Prob -11.839: The best thing about Bath is that it's a great place to live\n",
            "Beam 3, Prob -12.031: The best thing about Bath is that it's a place where you don\n",
            "Beam 4, Prob -12.366: The best thing about Bath is the fact that it's a place\n",
            "---\n",
            "Beam 0, Prob -9.753: The best thing about Bath is that it's a place where you can\n",
            "Beam 1, Prob -12.031: The best thing about Bath is that it's a place where you don't\n",
            "Beam 2, Prob -12.629: The best thing about Bath is that it's a place where you can get\n",
            "Beam 3, Prob -13.006: The best thing about Bath is that it's a great place to live.\n",
            "Beam 4, Prob -13.108: The best thing about Bath is the fact that it's a place where\n",
            "---\n",
            "Beam 0, Prob -12.274: The best thing about Bath is that it's a place where you can go\n",
            "Beam 1, Prob -12.603: The best thing about Bath is that it's a place where you don't have\n",
            "Beam 2, Prob -14.056: The best thing about Bath is the fact that it's a place where you\n",
            "Beam 3, Prob -14.324: The best thing about Bath is that it's a place where you can go and\n",
            "Beam 4, Prob -14.492: The best thing about Bath is that it's a great place to live. It\n",
            "---\n",
            "Beam 0, Prob -12.662: The best thing about Bath is that it's a place where you don't have to\n",
            "Beam 1, Prob -13.658: The best thing about Bath is that it's a place where you can go to\n",
            "Beam 2, Prob -14.469: The best thing about Bath is the fact that it's a place where you can\n",
            "Beam 3, Prob -14.785: The best thing about Bath is that it's a great place to live. It's\n",
            "Beam 4, Prob -14.896: The best thing about Bath is that it's a place where you don't have to be\n",
            "---\n",
            "Beam search result:\n",
            "The best thing about Bath is that it's a place where you don't have to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can read about more decoding strategies in this blog (which uses a recursive neural network, not a transformer, but the principles are the same).\n",
        "\n",
        "https://www.borealisai.com/research-blogs/tutorial-6-neural-natural-language-generation-decoding-algorithms/\n",
        "\n",
        "You can also look at other possible language models via hugging face:\n",
        "\n",
        "https://huggingface.co/docs/transformers/v4.25.1/en/model_summary#decoders-or-autoregressive-models\n"
      ],
      "metadata": {
        "id": "-SXpjZPYsMhv"
      }
    }
  ]
}